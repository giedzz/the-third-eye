{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71321c0c-7b67-4bc3-881d-e9d414c78ecc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Translate geotiff 16bit to grayscale 8bit, as tensorflow, can't handle 16bit images and 16bit rgb conversion to 8bit losses too much info ([Why training your CNN](https://towardsdatascience.com/why-training-your-cnn-with-16-bit-images-isnt-working-e91da350c49d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b15364c7-68b7-4b2d-ae72-ce62fed80dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_png = '../out/out_8bit/out_kaunas_sentinel_grayscale.png'\n",
    "input_geotiff = '../out/out_kaunas_sentinel.tif'\n",
    "training_data_images_output = '/media/agmis/mokslams/copernicus/the_third_eye/out/training_data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01d1f927-c17e-4dca-a766-c65cb220cc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7f2d6a3c0ab0> >"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "scale = '-scale min_val max_val'\n",
    "options_list = [\n",
    "    '-ot Byte',\n",
    "    '-of JPEG',\n",
    "    scale\n",
    "] \n",
    "options_string = \" \".join(options_list)\n",
    "\n",
    "gdal.Translate(output_png,\n",
    "               input_geotiff,\n",
    "               options=options_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755a821-63d8-40b8-a9ac-60e8529a57a1",
   "metadata": {},
   "source": [
    "Prepare annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7ee9df0-ecbd-4074-81ff-d3443816e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_annotations_png = '../masks/norm_img.png'\n",
    "input_annotations_geotiff = '../masks/polygon_kauno_r_m.tif'\n",
    "training_data_annotations_output = '/media/agmis/mokslams/copernicus/the_third_eye/out/training_data/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fee05c2-bcd8-4f15-999c-ee0ba79637f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7f2d6a296c30> >"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = '-scale min_val max_val'\n",
    "options_list = [\n",
    "    '-ot Byte',\n",
    "    '-of JPEG',\n",
    "    scale\n",
    "] \n",
    "options_string = \" \".join(options_list)\n",
    "\n",
    "gdal.Translate(output_annotations_png,\n",
    "               input_annotations_geotiff,\n",
    "               options=options_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f41713-c1cb-4184-b35f-d68842230a43",
   "metadata": {},
   "source": [
    "#### Cut grayscale image to pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "faccf554-aadc-45e1-99c9-41789932ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def crop(path, input, annotations=False):\n",
    "    height = 255\n",
    "    width = 255\n",
    "    im = Image.open(input)\n",
    "    imgwidth, imgheight = im.size\n",
    "    for i in range(0,imgheight,height):\n",
    "        for j in range(0,imgwidth,width):\n",
    "            box = (j, i, j+width, i+height)\n",
    "            a = im.crop(box)\n",
    "            try:\n",
    "                if annotations:\n",
    "                    if a.getbbox():\n",
    "                        a.save(os.path.join(path, f'{i}{j}.png'))\n",
    "                else:\n",
    "                    a.save(os.path.join(path, f'{i}{j}.png'))\n",
    "            except Exception as e:\n",
    "                print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88ca16e3-87bb-4700-8e88-3db1fbdcea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(training_data_images_output, output_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3aca1254-2a22-4c3d-af93-b5f9ec1743b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(training_data_annotations_output, output_annotations_png, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db861a7-2407-4d67-8be9-9933077762f4",
   "metadata": {},
   "source": [
    "#### Transfer images with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09c63fc3-bcca-42b1-8e19-d828e983d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "training_data_images_that_have_annotations_output = '/media/agmis/mokslams/copernicus/the_third_eye/out/training_data/images_that_have_annotations'\n",
    "for file in os.listdir(training_data_annotations_output):\n",
    "    shutil.copy(os.path.join(training_data_images_output, file), os.path.join(training_data_images_that_have_annotations_output, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3204a-e8c1-4f99-9053-8bbb9f3be687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
